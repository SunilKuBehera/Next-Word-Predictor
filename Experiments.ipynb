{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxkUlJpVxdQM",
        "outputId": "b4d660cd-a688-4bb9-ef25-6cd9b7d83e02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to\n",
            "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
          ]
        }
      ],
      "source": [
        "# Data Collection\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lhm8Y629yL6a"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "\n",
        "# save to a file\n",
        "with open('hamlet.txt', 'w') as file:\n",
        "  file.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Tj03dFkfyL3G"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6H2qXcDhyL0i"
      },
      "outputs": [],
      "source": [
        "# Load the data & lower them\n",
        "with open('hamlet.txt', 'r') as file:\n",
        "  text = file.read().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w20xt5geyLxq"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1 # creating index of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RxOeRt4Jzna3"
      },
      "outputs": [],
      "source": [
        "# Creating input sequences\n",
        "inputSequences = []\n",
        "for line in text.split('\\n'):\n",
        "  tokenList = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(tokenList)):\n",
        "    nGramSequence = tokenList[:i+1]\n",
        "    inputSequences.append(nGramSequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TdU11M4YznVE"
      },
      "outputs": [],
      "source": [
        "# Pad sequences\n",
        "maxSequenceLength = max([len(x) for x in inputSequences])\n",
        "inputSequences = np.array(pad_sequences(inputSequences, maxlen=maxSequenceLength, padding='pre'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U7_aLrvP0vMs"
      },
      "outputs": [],
      "source": [
        "# Create predictors and label\n",
        "X, y = inputSequences[:,:-1], inputSequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8exq7OX0vJW",
        "outputId": "a79a59d5-9ac8-43fe-dbab-bcab34d22f31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 687,    4,   45, ..., 1047,    4,  193])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhJa-IQO2E68",
        "outputId": "fa35cbc7-c56d-4d8d-9421-9bd3b4ac16f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = keras.utils.to_categorical(y, num_classes=total_words)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GUFaJDwU2JOA"
      },
      "outputs": [],
      "source": [
        "# Split the data into  train & test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm_saAjO3jxX"
      },
      "source": [
        "### Train LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HQZi0vlv3ewY"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100))\n",
        "model.add(LSTM(150, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='linear'))\n",
        "\n",
        "# Compile with numerically stable loss and metric\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=optimizer, metrics=['accuracy']) # Added 'accuracy' metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b8360122",
        "outputId": "4ae6f745-8fd6-44c0-d781-d855135fab5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 121ms/step - accuracy: 0.0231 - loss: 7.4125 - val_accuracy: 0.0336 - val_loss: 6.7741\n",
            "Epoch 2/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 142ms/step - accuracy: 0.0321 - loss: 6.6028 - val_accuracy: 0.0336 - val_loss: 6.8056\n",
            "Epoch 3/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 118ms/step - accuracy: 0.0335 - loss: 6.4862 - val_accuracy: 0.0336 - val_loss: 6.8107\n",
            "Epoch 4/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.0343 - loss: 6.4027 - val_accuracy: 0.0410 - val_loss: 6.8569\n",
            "Epoch 5/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 135ms/step - accuracy: 0.0442 - loss: 6.3187 - val_accuracy: 0.0470 - val_loss: 6.8273\n",
            "Epoch 6/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 117ms/step - accuracy: 0.0478 - loss: 6.2216 - val_accuracy: 0.0459 - val_loss: 6.8464\n",
            "Epoch 7/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.0546 - loss: 6.1295 - val_accuracy: 0.0468 - val_loss: 6.8397\n",
            "Epoch 8/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 128ms/step - accuracy: 0.0524 - loss: 6.0782 - val_accuracy: 0.0468 - val_loss: 6.8549\n",
            "Epoch 9/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 116ms/step - accuracy: 0.0509 - loss: 6.0426 - val_accuracy: 0.0499 - val_loss: 6.8674\n",
            "Epoch 10/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 151ms/step - accuracy: 0.0548 - loss: 5.9479 - val_accuracy: 0.0528 - val_loss: 6.8736\n",
            "Epoch 11/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 117ms/step - accuracy: 0.0591 - loss: 5.8537 - val_accuracy: 0.0519 - val_loss: 6.8993\n",
            "Epoch 12/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 147ms/step - accuracy: 0.0595 - loss: 5.8119 - val_accuracy: 0.0544 - val_loss: 6.9359\n",
            "Epoch 13/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 126ms/step - accuracy: 0.0684 - loss: 5.7466 - val_accuracy: 0.0595 - val_loss: 6.9510\n",
            "Epoch 14/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 118ms/step - accuracy: 0.0731 - loss: 5.6899 - val_accuracy: 0.0622 - val_loss: 6.9899\n",
            "Epoch 15/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 131ms/step - accuracy: 0.0749 - loss: 5.6306 - val_accuracy: 0.0614 - val_loss: 7.0118\n",
            "Epoch 16/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 152ms/step - accuracy: 0.0797 - loss: 5.5813 - val_accuracy: 0.0649 - val_loss: 7.0416\n",
            "Epoch 17/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.0843 - loss: 5.5195 - val_accuracy: 0.0651 - val_loss: 7.0813\n",
            "Epoch 18/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.0922 - loss: 5.4528 - val_accuracy: 0.0664 - val_loss: 7.1244\n",
            "Epoch 19/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 136ms/step - accuracy: 0.0898 - loss: 5.3998 - val_accuracy: 0.0668 - val_loss: 7.1346\n",
            "Epoch 20/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 151ms/step - accuracy: 0.0996 - loss: 5.3677 - val_accuracy: 0.0643 - val_loss: 7.1630\n",
            "Epoch 21/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 117ms/step - accuracy: 0.0972 - loss: 5.2840 - val_accuracy: 0.0631 - val_loss: 7.1786\n",
            "Epoch 22/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.1044 - loss: 5.2271 - val_accuracy: 0.0622 - val_loss: 7.2220\n",
            "Epoch 23/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 117ms/step - accuracy: 0.1058 - loss: 5.1827 - val_accuracy: 0.0672 - val_loss: 7.2492\n",
            "Epoch 24/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.1129 - loss: 5.1489 - val_accuracy: 0.0663 - val_loss: 7.2976\n",
            "Epoch 25/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.1100 - loss: 5.0865 - val_accuracy: 0.0635 - val_loss: 7.3095\n",
            "Epoch 26/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.1205 - loss: 5.0199 - val_accuracy: 0.0639 - val_loss: 7.3608\n",
            "Epoch 27/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 125ms/step - accuracy: 0.1147 - loss: 4.9981 - val_accuracy: 0.0684 - val_loss: 7.3782\n",
            "Epoch 28/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 118ms/step - accuracy: 0.1195 - loss: 4.9271 - val_accuracy: 0.0649 - val_loss: 7.4101\n",
            "Epoch 29/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 119ms/step - accuracy: 0.1199 - loss: 4.8944 - val_accuracy: 0.0678 - val_loss: 7.4492\n",
            "Epoch 30/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - accuracy: 0.1266 - loss: 4.8411 - val_accuracy: 0.0674 - val_loss: 7.4719\n",
            "Epoch 31/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.1255 - loss: 4.8104 - val_accuracy: 0.0649 - val_loss: 7.5164\n",
            "Epoch 32/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.1338 - loss: 4.7720 - val_accuracy: 0.0651 - val_loss: 7.5466\n",
            "Epoch 33/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.1361 - loss: 4.7113 - val_accuracy: 0.0657 - val_loss: 7.5743\n",
            "Epoch 34/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 118ms/step - accuracy: 0.1376 - loss: 4.6680 - val_accuracy: 0.0635 - val_loss: 7.6127\n",
            "Epoch 35/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 118ms/step - accuracy: 0.1400 - loss: 4.6352 - val_accuracy: 0.0639 - val_loss: 7.6537\n",
            "Epoch 36/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 125ms/step - accuracy: 0.1424 - loss: 4.5853 - val_accuracy: 0.0651 - val_loss: 7.6801\n",
            "Epoch 37/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 118ms/step - accuracy: 0.1495 - loss: 4.5311 - val_accuracy: 0.0647 - val_loss: 7.7102\n",
            "Epoch 38/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - accuracy: 0.1550 - loss: 4.4794 - val_accuracy: 0.0647 - val_loss: 7.7575\n",
            "Epoch 39/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.1575 - loss: 4.4501 - val_accuracy: 0.0659 - val_loss: 7.7891\n",
            "Epoch 40/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.1586 - loss: 4.4207 - val_accuracy: 0.0645 - val_loss: 7.8177\n",
            "Epoch 41/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - accuracy: 0.1614 - loss: 4.3683 - val_accuracy: 0.0643 - val_loss: 7.8684\n",
            "Epoch 42/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.1685 - loss: 4.3234 - val_accuracy: 0.0651 - val_loss: 7.8892\n",
            "Epoch 43/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.1722 - loss: 4.2728 - val_accuracy: 0.0635 - val_loss: 7.9351\n",
            "Epoch 44/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 126ms/step - accuracy: 0.1734 - loss: 4.2473 - val_accuracy: 0.0614 - val_loss: 7.9596\n",
            "Epoch 45/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.1737 - loss: 4.2354 - val_accuracy: 0.0641 - val_loss: 7.9985\n",
            "Epoch 46/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - accuracy: 0.1798 - loss: 4.1983 - val_accuracy: 0.0633 - val_loss: 8.0449\n",
            "Epoch 47/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.1892 - loss: 4.1543 - val_accuracy: 0.0639 - val_loss: 8.0698\n",
            "Epoch 48/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.1978 - loss: 4.1127 - val_accuracy: 0.0651 - val_loss: 8.1290\n",
            "Epoch 49/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 127ms/step - accuracy: 0.1996 - loss: 4.0661 - val_accuracy: 0.0637 - val_loss: 8.1621\n",
            "Epoch 50/50\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 113ms/step - accuracy: 0.2077 - loss: 4.0384 - val_accuracy: 0.0635 - val_loss: 8.2058\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "FS2mEYZe7OKU",
        "outputId": "56ba8568-9034-4acd-c016-4c5f6a2f21ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">486,618</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_24 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m481,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_41 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_42 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)           │       \u001b[38;5;34m486,618\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,658,256</span> (13.96 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,658,256\u001b[0m (13.96 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,438,838</span> (9.30 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,438,838\u001b[0m (9.30 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOGXis6SEao9",
        "outputId": "8154daa1-670b-4f25-9e7a-0412d15c11a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.0663 - loss: 8.2921\n",
            "Model Loss: 8.205774307250977, Model Accuracy: 0.06353215128183365\n"
          ]
        }
      ],
      "source": [
        "# Calculate model loss & accuracy\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Model Loss: {loss}, Model Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "fcqyAOqv8oWa"
      },
      "outputs": [],
      "source": [
        "# Create a reverse word index for efficient lookup\n",
        "reverse_word_index = dict([(index, word) for word, index in tokenizer.word_index.items()])\n",
        "\n",
        "# function to predict the next word\n",
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "  token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "  # Pad sequences to the correct length (max_sequence_len - 1 for the input)\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  prediction = model.predict(token_list,verbose=0)\n",
        "  predicted_word_index = np.argmax(prediction, axis=1)[0] # Get the single predicted index\n",
        "  # Use the reverse word index for efficient lookup\n",
        "  predicted_word = reverse_word_index.get(predicted_word_index)\n",
        "  return predicted_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2yOWYT0FXPa",
        "outputId": "46443a48-ac38-4c7f-a325-8ab30b841d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Next Word: made\n"
          ]
        }
      ],
      "source": [
        "input_text = \"To be or not to be\"\n",
        "max_sequence_len = model.input_shape[1]+1\n",
        "predicted_word = predict_next_word(model, tokenizer, input_text,    max_sequence_len)\n",
        "print(f'Predicted Next Word: {predicted_word}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B6pwrNu7Fr3Q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
            "  return saving_lib.save_model(model, filepath)\n"
          ]
        }
      ],
      "source": [
        "# save the model\n",
        "model.save('nextWord_LSTM_model.keras')\n",
        "\n",
        "# Save the tokenizer\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
